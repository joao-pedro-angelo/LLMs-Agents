![image](https://github.com/user-attachments/assets/016abac0-40cf-4d0f-ad73-d21986b7dc27)

![image](https://github.com/user-attachments/assets/90769ff2-0680-48e2-a2ae-1596991e5815)

![image](https://github.com/user-attachments/assets/c1746247-719c-4d73-90e3-afe7f602a2d0)

---
## O que o LLM faz em decoding

O modelo, ao decodificar, tenta encontrar a sequÃªncia mais provÃ¡vel considerando tanto o caminho de raciocÃ­nio (reasoning path)
quanto a resposta final (final answer), dados o problema (problem). Em termos matemÃ¡ticos:

argÂ maxÂ ğ‘ƒ(reasoningÂ path,Â finalÂ answerÂ |Â problem)

Isso significa que o LLM avalia a probabilidade conjunta de produzir tanto os passos intermediÃ¡rios quanto a resposta final
para um dado problema.

---
## O que queremos

Em vez de priorizar o caminho de raciocÃ­nio junto com a resposta final, o objetivo Ã© maximizar diretamente a probabilidade
da resposta final correta, considerando o problema. Isso Ã© representado como:

argÂ maxÂ ğ‘ƒ(finalÂ answerÂ |Â problem)

Durante o raciocÃ­nio, um LLM pode gerar passos intermediÃ¡rios desnecessÃ¡rios ou errados,
que impactam negativamente na resposta final.
Ao eliminar a dependÃªncia do reasoning path, o modelo pode potencialmente melhorar sua precisÃ£o.

Esse conceito estÃ¡ diretamente relacionado Ã  ideia de raciocÃ­nio sem prompting, usando estratÃ©gias como top-k decoding,
onde caminhos de raciocÃ­nio alternativos sÃ£o explorados para melhorar o desempenho em tarefas complexas.

---
## Como calcular P(final answer | problem)

![image](https://github.com/user-attachments/assets/74172358-7809-4283-95f4-d595c9049a1b)

![image](https://github.com/user-attachments/assets/4f9b76ba-0cdc-4438-9f61-0aa2685e0586)

O texto destaca que amostragem (sampling) Ã© o mÃ©todo utilizado para estimar essa soma,
jÃ¡ que Ã© computacionalmente inviÃ¡vel explorar todos os caminhos de raciocÃ­nio possÃ­veis diretamente.
